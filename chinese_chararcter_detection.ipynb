{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deadline: 23:59 on 2021 October 18\n",
    "\n",
    "# TODO\n",
    "\n",
    "* Prepare data\n",
    "    * Images to tensors\n",
    "    * Bounding box infomration to numpy array\n",
    "* Implement two different models\n",
    "    * Representation of the images as training input\n",
    "    * Representation of the bounding boxes as objective\n",
    "        * HINT: the binary classification of pixels as belonging to a bounding box or not\n",
    "* Test and evaluate\n",
    "    * Way 1: choose a probability threshold to decide whether a pixel is inside the bounding box or not, and then take recall/precision/X11/accuracy\n",
    "    * Way 2: report it in terms of error, such as mean squared error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open(info_filename, 'r') as info_file:\\n    data = info_file.read()\\ninfo_obj = json.loads(data)\\n\\ndf_train = pd.DataFrame.from_dict(info_obj['train'])\\ndf_val = pd.DataFrame.from_dict(info_obj['val'])\\ndf = pd.concat([df_train, df_val])\\ndf = df[pd.DataFrame(df.file_name.to_list()).isin(image_files).any(1).values]\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maybe not needed\n",
    "'''\n",
    "with open(info_filename, 'r') as info_file:\n",
    "    data = info_file.read()\n",
    "info_obj = json.loads(data)\n",
    "\n",
    "df_train = pd.DataFrame.from_dict(info_obj['train'])\n",
    "df_val = pd.DataFrame.from_dict(info_obj['val'])\n",
    "df = pd.concat([df_train, df_val])\n",
    "df = df[pd.DataFrame(df.file_name.to_list()).isin(image_files).any(1).values]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mplpath\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "source_dir = \"/scratch/lt2326-h21/a1/\"\n",
    "image_dir = \"/scratch/lt2326-h21/a1/images/\"\n",
    "info_filename = \"/scratch/lt2326-h21/a1/info.json\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in listdir(image_dir) if isfile(join(image_dir, f))]\n",
    "image_files = image_files[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data_from_jsonl(jsonl_file, included_images):\n",
    "   image_data = []\n",
    "   images = []\n",
    "   with jsonlines.open(jsonl_file) as reader:\n",
    "      for line in reader.iter(type=dict):\n",
    "         if (line.get('file_name') in included_images):\n",
    "            image_data.append(line)\n",
    "            image = mpimg.imread(image_dir + line.get('file_name'))\n",
    "            images.append(image)\n",
    "            \n",
    "   return image_data, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup coordinates grid to use for getting polygon matrix\n",
    "height = 2048\n",
    "width = 2048\n",
    "rows = np.arange(height)\n",
    "cols = np.arange(width)\n",
    "coordinates_grid = np.empty((height, width, 2), dtype=np.intp)\n",
    "coordinates_grid[..., 0] = rows[:, None]\n",
    "coordinates_grid[..., 1] = cols\n",
    "coordinates_grid.shape = (height*width, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data = [] # lista av tuples, med bild och ground truth\n",
    "def get_image_polygon_data(image_data):\n",
    "    image_polygon_data = []\n",
    "\n",
    "    for entry in image_data:\n",
    "        image_dict = { \n",
    "            'file_name': entry['file_name'],\n",
    "            'polygons': []\n",
    "            }\n",
    "        for annotation in entry['annotations']:\n",
    "            for bbox in annotation:\n",
    "                if(bbox['is_chinese']):\n",
    "                    image_dict['polygons'].append(bbox['polygon'])\n",
    "        image_polygon_data.append(image_dict)\n",
    "    return image_polygon_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(polygon_data):\n",
    "    training_data = []\n",
    "\n",
    "    for image in polygon_data:\n",
    "        img = mpimg.imread(image_dir + image['file_name'])\n",
    "        img_tensor = convert_tensor(img)\n",
    "        #chinese_chars = np.empty((height, width), dtype=np.intp)\n",
    "        chinese_chars = np.empty((height*width))\n",
    "        for polygon in image['polygons']:\n",
    "            path = mplpath.Path(polygon)\n",
    "            polygon_grid = np.asarray(path.contains_points(coordinates_grid), int)\n",
    "            chinese_chars += polygon_grid\n",
    "            \n",
    "        chinese_chars.shape = (height, width)\n",
    "        training_data.append((img_tensor, chinese_chars))\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(image_data):\n",
    "    truth_grid = np.zeros((height, width), dtype=np.intp)\n",
    "    for polygon in image_data['polygons']:\n",
    "        path = mplpath.Path(polygon)\n",
    "        polygon_grid = np.asarray(path.contains_points(coordinates_grid), int)\n",
    "        polygon_grid.shape = (height, width)\n",
    "        truth_grid += polygon_grid\n",
    "    \n",
    "    truth_grid = np.resize(truth_grid, (200,200))\n",
    "    return truth_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "image_training_data, images = get_image_data_from_jsonl(source_dir + \"train.jsonl\", image_files)\n",
    "image_val_data, _ = get_image_data_from_jsonl(source_dir + \"val.jsonl\", image_files)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_polygons = get_image_polygon_data(image_training_data)\n",
    "#get_ground_truth(training_data_polygons[0])\n",
    "#training_data = create_training_data(training_data_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: https://amaarora.github.io/2020/09/13/unet.html\n",
    "\n",
    "# Input - bilder / tre dimensionell array\n",
    "# Output - Koordinater till bounding box\n",
    "# Dimension på bilderna: 2048 x 2048 x 3\n",
    "# Dimension på bounding box: 2 x 4\n",
    "# Dimension på output: 2048 x 2048 x 1 (binär data över var kinesiska tecken var)\n",
    "\n",
    "# Två saker!\n",
    "#   1. Hitta tecken\n",
    "#   2. Avgör om det är kinesiskt eller inte\n",
    "\n",
    "class charDetectionCNN(nn.Module):\n",
    "\n",
    "# RuntimeError: Expected 4-dimensional input for 4-dimensional weight [3, 3, 3, 3], \n",
    "# but got 3-dimensional input of size [3, 2048, 2048] instead\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        chan_0 = 3\n",
    "        chan_1 = 16\n",
    "        chan_2 = 32\n",
    "        self.out_sz = (200, 200)\n",
    "\n",
    "        # Encode Block 1\n",
    "        self.conv_encode_11 = nn.Conv2d(chan_0, chan_1, 3)\n",
    "        self.relu_encode_1  = nn.ReLU()\n",
    "        self.conv_encode_12 = nn.Conv2d(chan_1, chan_1, 3)\n",
    "        # Encode Block 2\n",
    "        self.conv_encode_21 = nn.Conv2d(chan_1, chan_2, 3)\n",
    "        self.relu_encode_2  = nn.ReLU()\n",
    "        self.conv_encode_22 = nn.Conv2d(chan_2, chan_2, 3)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Decoded Block 1\n",
    "        self.upconv1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv_decode_11 = nn.Conv2d(chan_2, chan_1, 3)\n",
    "        self.relu_decode_1  = nn.ReLU()\n",
    "        self.conv_decode_12 = nn.Conv2d(chan_1, chan_1, 3)\n",
    "\n",
    "        # Decoded Block 2\n",
    "        self.upconv2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv_decode_21 = nn.Conv2d(chan_1, chan_0, 3)\n",
    "        self.relu_decode_2  = nn.ReLU()\n",
    "        self.conv_decode_22 = nn.Conv2d(chan_0, chan_0, 3)\n",
    "\n",
    "        # Final\n",
    "        self.final = nn.Conv2d(chan_0, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # encode 1\n",
    "\n",
    "        #print(\"pre: conv_encode 1:\", inp.shape)\n",
    "        enc1 = self.conv_encode_12(self.relu_encode_1(self.conv_encode_11(inp)))\n",
    "        \n",
    "        #print(\"pre: self.pool(enc1):\", enc1.shape)\n",
    "        enc2 = self.pool(enc1)\n",
    "        # encode 2\n",
    "        #print(\"pre: conv_encode 2:\", enc2.shape)\n",
    "        enc2 = self.conv_encode_22(self.relu_encode_2(self.conv_encode_21(enc2)))\n",
    "        #print(\"pre: self.pool(enc2):\", enc2.shape)\n",
    "        #enc2 = self.pool(enc2)\n",
    "        #print(\"postpool:\", enc2.shape)\n",
    "\n",
    "\n",
    "        # decode 1\n",
    "        #print(\"pre: upconv1(enc2):\", enc2.shape)\n",
    "        x = self.upconv1(enc2)\n",
    "        #print(\"post: upconv1(enc2):\", x.shape)\n",
    "\n",
    "        # crop\n",
    "        #_, _, h, w = x.shape\n",
    "        #print(\"In decode 1, x.shape:\", x.shape)\n",
    "        #temp = transforms.CenterCrop([h, w])(enc2)\n",
    "        #print(temp.shape)\n",
    "        ## concat\n",
    "        #x = torch.cat([x, temp], dim=1)\n",
    "        #print(\"In decode 1, x.shape:\", x.shape)\n",
    "        x = self.conv_decode_12(self.relu_decode_1(self.conv_decode_11(x)))\n",
    "\n",
    "        #x = self.conv_decode_11(self.relu_decode_1(self.conv_decode_12(x)))\n",
    "        # Given groups=1, weight of size [128, 1024, 3, 3], expected input[1, 2048, 188, 188] to have 1024 channels, but got 2048 channels instead\n",
    "        \n",
    "        # decode 2\n",
    "        x = self.upconv2(x)\n",
    "        #_, _, h, w = x.shape\n",
    "        #temp = transforms.CenterCrop([h, w])(enc1)\n",
    "        #x = torch.cat([x, temp], dim=1)\n",
    "        x = self.conv_decode_22(self.relu_decode_2(self.conv_decode_21(x)))\n",
    "\n",
    "        out = self.final(x)\n",
    "        out = self.sigmoid(out)\n",
    "        out = F.interpolate(out, self.out_sz)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tensor_image(image_data):\n",
    "    image = mpimg.imread(image_dir + image_data['file_name'])\n",
    "    rsize = np.resize(image, (200,200,3))\n",
    "    return convert_tensor(rsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = {}\n",
    "for img in training_data_polygons:\n",
    "    ground_truth = torch.Tensor(get_ground_truth(img))\n",
    "    ground_truth = ground_truth.unsqueeze(0)\n",
    "    ground_truth = ground_truth.unsqueeze(0)\n",
    "    gts[img['file_name']] = ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orig size = 2048 x 2048 x 3\n",
    "# Resized = 256 x 256 x 3\n",
    "# input\n",
    "\n",
    "\n",
    "# number of neurons in each layer\n",
    "input_num_units = 256*256\n",
    "hidden_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "# set remaining variables\n",
    "epochs = 10\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "model = charDetectionCNN()\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "print(len(training_data_polygons))\n",
    "for i in range(epochs):\n",
    "    for image in training_data_polygons:\n",
    "        tensor_image = get_tensor_image(image)\n",
    "        output = model(tensor_image.unsqueeze(0))\n",
    "        loss = loss_function(output, gts[image['file_name']])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO imorgon 20211012\n",
    "\n",
    "1. Gör bilderna mindre (2048 x 2048 -> 200 x 200)\n",
    "2. Få första modellen att fungera\n",
    "\n",
    "3. Påbörja projektet\n",
    "    * Bestäm vad jag ska göra\n",
    "    * Skaffa data (api?)\n",
    "\n",
    "x. Försök optimera \"ground_truth\"-functionen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
